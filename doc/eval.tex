This section presents an example of using OTPO in order to optimize the InfiniBand parameters of Open MPI on a given platform. The test was run on the shark cluster at the University of Houston. Shark consists of 24 dual-core 2.2GHz AMD Opteron nodes connected by a 4xInfiniBand and a Gigabit Ethernet network interconnect.

The MCA parameters used for the evaluation is a subset of the parameters mentioned in section~\ref{sec:motivation}, namely {\tt btl\_openib\_receive\_queues}. As discussed in section~\ref{sec:motivation}, this parameter is a combination of several receive queues, where each queue in turn takes other parameters. In order for OTPO to handle this parameter, it has to be specified as an aggregate of other virtual parameters. In our test, we decided to use two receive queues, one Per-peer queue and one shared receive queue. The following specification was used for the MCA parameter:

\begin{itemize}
\item {\tt btl\_openib\_rq\_1\_type}: P
\item {\tt btl\_openib\_rq\_1\_size}: 65536 $->$ 262144 (increment * 2)
\item {\tt btl\_openib\_rq\_1\_num}: 1 $->$ 256 (increment * 2)
\item {\tt btl\_openib\_rq\_1\_low\_wat}: 1 $->$ 64 (increment * 2)
\item {\tt btl\_openib\_rq\_2\_type}: S
\item {\tt btl\_openib\_rq\_2\_size}: 65536 $->$ 262144 (increment * 2)
\item {\tt btl\_openib\_rq\_2\_num}: 1 $->$ 256 (increment * 2)
\item {\tt btl\_openib\_rq\_2\_low\_wat}: 1 $->$ 64 (increment * 2)
\item {\tt btl\_openib\_rq\_2\_max\_pending\_sends}: 1 $->$ 32 (increment * 2)
\item {\tt btl\_openib\_receive\_queues}: aggregate of the above parameters
\end{itemize}

This configuration yields 37730 combinations, after removing unnecessary combinations that would lead to wrong or inaccurate results.  The total time that the benchmark took was {\tt 6 hrs 32 min 11 sec}.

\begin{table}[tb]
\centering
\begin{tabular}{|c|c|} \hline
Latency & Number of Combinations \\
\hline
3.87us  & 1\\
\hline
3.88us  & 619\\
\hline
3.89us  & 9702\\
\hline
3.90us  & 10977\\
\hline
3.91us  & 7907\\
\hline
3.92us  & 5076\\
\hline
\end{tabular}  
\caption{OTPO results of the best parameter combinations}
\label{table:results} 
\end{table}

The results that are summarized in table ~\ref{table:results} shows the number
of combinations that are in the range of 0.05 micro-seconds of the best
latency. The best possible combination was with the following combination of values:
$P,131072,64,4:S,262144,256,64,16$\\
The results suggest the best attributes for the two queue pairs:\\
Per-peer queue:
\begin{itemize}
\item The size of the receive buffers to be posted is 131072 Bytes.
\item The maximum number of buffers posted for incoming message fragments is
  64.
\item the number of available buffers left on the queue, before Open MPI
  reposts buffers up to the maximum (previous parameter), is four.
\end{itemize}
Shared Receive Queue:
\begin{itemize}
\item The size of the receive buffers to be posted is 262144 Bytes.
\item The maximum number of buffers posted for incoming message fragments is
  256.
\item the number of available buffers left on the queue, before Open MPI
  reposts buffers up to the maximum (previous parameter), is 64.
\item the maximum number of outstanding sends that are allowed at a given time
  is 16.
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
