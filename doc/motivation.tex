\label{sec:motivation}

In this section, we will detail some of the parameters of the {\tt openib} BTL module of Open MPI and discuss their potential impact on the performance of an application.  A BTL module in Open MPI is the lowest level layer that is responsible for transferring bytes from one process to another without having any knowledge of MPI semantics or other functionality. 

Open MPI internally ranks network interconnects based on the best latency achievable by that network. Upon startup of an application, the MPI library determines the list of available networks on each process and to each process. Therefore, the same process might use different network interconnects for communication to different processes. The default behavior of Open MPI always chooses the network with the lowest latency. If a user wants to enforce the usage of a particular network respectively BTL module in Open MPI he/she has to set an MCA runtime parameter. As an example, in order to enforce the usage of the InfiniBand module, the user just has to add the following line to the runtime command: 
{\tt --mca btl openib}. Note that this will then disable the lower latency shared memory module for intra-node communication.

There are more than 50 MCA parameters that are related to the InfiniBand BTL
module, all of which can be modified at runtime. Modifying some of
the parameters may not have an effect on the performance of an application,
but others may. 

Some of the parameters that configure the RDMA protocol within the {\tt openib} module~\cite{rdma}
include:
\begin{itemize}
\item {\tt btl\_openib\_ib\_max\_rdma\_dst\_opts}: maximum number of pending
  RDMA destination operations.
\item {\tt btl\_openib\_use\_eager\_rdma}: whether to use the RDMA protocol for
  eager (short) messages.
\item {\tt btl\_openib\_eager\_rdma\_threshold}: use RDMA for short messages
  after this number of messages are received from a given peer.
\item {\tt btl\_openib\_max\_eager\_rdma}: maximum number of peers allowed to
  use RDMA for short messages.
\item {\tt btl\_openib\_eager\_rdma\_num}: Number of RDMA buffers to allocate
  for short messages.
\end{itemize}

Another parameter  modifies the number and the configuration of receive
queues ({\tt btl\_openib\_receive\_queues}). This parameter allows the
specification of multiple receive queues for an InfiniBand port, where
each queue has multiple tunable numeric values. There are two types of queues:
\begin{enumerate}
\item Per-peer (P): each queue is dedicated to receiving messages from a
  single, specific peer MPI process. A P queue can take the following
  parameters:\\
  {\tt P<size>,<num\_buffers>,[<low\_watermark>[,<window\_size>,} \\
  {\tt [<reserve>]]]}
\item Shared receive queue (S): a receive queue is shared between all MPI
  sending processes. An SRQ can take the following parameters: \\
  {\tt S<size>,<num\_buffers>,[<low\_watermark>[,<max\_pending\_sends>]]}
\end{enumerate}

All parameters have default values in Open MPI. However, different combinations of parameter values might lead to the best performance  on different platforms. Although the number of parameters seems large, the approach offered by Open MPI has many advantages. Setting a reasonable default value leads from the perspective of the average end-user to the same 
result as hard-coding the value in the sources. However, exporting those variables as runtime parameters introduces the potential to optimize the values without having to recompile the library.
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
